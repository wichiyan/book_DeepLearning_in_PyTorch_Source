{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入全局库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install subword-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备模块\n",
    "以下三个代码块，是为了获取用于机器翻译的数据集，我们已经按以下代码跑通，相应数据已在此代码所在文件夹中。所以可以不必执行此代码。供了解。\n",
    "相应数据包括：\n",
    "1. ted-en_zh.codes\n",
    "2. dict.zh-cn\n",
    "3. dict.en\n",
    "4. ted-data/*.bped一系列数据\n",
    "\n",
    "如果你想自己尝试，可以在文件中删除以上数据文件，自己动手尝试下~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat ted-data/train.* ted-data/dev.* | subword-nmt learn-bpe -s 32000 > ted-en_zh.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# for f in ted-data/*;\n",
    "# do\n",
    "#     subword-nmt apply-bpe -c ted-en_zh.codes < $f > $f.bped;\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cat ted-data/train.zh-cn.bped ted-data/dev.zh-cn.bped | subword-nmt get-vocab -o dict.zh-cn\n",
    "# cat ted-data/train.en.bped ted-data/dev.en.bped | subword-nmt get-vocab -o dict.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下三个代码块，适合于Win系统是为了获取用于机器翻译的数据集，我们已经按以下代码跑通，相应数据已在此代码所在文件夹中。所以可以不必执行此代码。供了解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cmd\n",
    "# type ted-data\\train.* ted-data\\dev.* | subword-nmt learn-bpe -s 32000 >> ted-en_zh.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cmd\n",
    "# for %f in (ted-data/*)\n",
    "# do\n",
    "#     subword-nmt apply-bpe -c ted-en_zh.codes < ted-data\\%f > ted-data\\%f.bped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cmd\n",
    "# type ted-data\\train.zh-cn.bped ted-data\\dev.zh-cn.bped | subword-nmt get-vocab -o dict.zh-cn\n",
    "# type ted-data\\train.en.bped ted-data\\dev.en.bped | subword-nmt get-vocab -o dict.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本构建定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义词嵌入层，\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        #下方之所以乘个缩放值，主要是embedding的值一般太小，需要适度放大，再和位置编码相加，会合适些\n",
    "        #因为和标量的运算会自动对齐设备，所以下面不用考虑设备迁移\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义位置编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  PE(pos,2i)   = sin( \\frac{pos} {1000^{\\frac{2i}{dim}}})  $$\n",
    "$$  PE(pos,2i+1) = cos( \\frac{pos} {1000^{\\frac{2i}{dim}}})  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义位置编码类\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0) #将形状修改为1,L,D,为了便于后续的广播，因为对于不同的样本，位置编码其实一样\n",
    "        self.register_buffer('pe', pe) #将位置编码结果，放入缓存中，且不会纳入模型参数内，主要是确保随模型迁移设备\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x + torch.tensor(self.pe[:, :x.size(1)], \n",
    "        #                  requires_grad=False)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义注意力层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力计算统一计算公式如下：\n",
    "$$  Attention(Q,K,V) = softmax( \\frac{ QK^{T} } {\\sqrt{d_{model}}} + mask\\_matirx )  V $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义注意力计算层，主要返回注意力矩阵，以及注意力加权后结果\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        #如果有掩码矩阵，则对掩码矩阵是0的位置，填充为一个很大的负数，相当于对该位置不纳入注意力计算\n",
    "        scores = scores.masked_fill(mask == 0, -1e4)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn   #对应形状分别为N,L,D  以及 N,L,L\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "    \n",
    "#实现多头注意力\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        # self.linears = [nn.Linear(d_model, d_model) for i in range(4) ] #如果使用这种方式，不会被包含到model.child里面，也就不会随设备迁移，尤其注意\n",
    "        self.linears = clones( nn.Linear(d_model, d_model), 4 )\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model = h * d_k \n",
    "        # 注意，论文里写的是对每个头单独做线性映射，但此处是一次性做投射，然后切分为多个头，本质没啥区别\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)  #此处最后对注意力又投射了一次，主要还是增加模型的表现力，可以考虑不加\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义层归一化和残差模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现LN层，layernorm主要是对一个批次内的每个样本单独做归一化\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        #使用Parameter定义，会自动纳入model的Parameters里，便于后续训练等\n",
    "        #针对每个特征，即D，独立有自己的a和b，且值可以学习\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)  #N,L,1\n",
    "        std = x.std(-1, keepdim=True)  #N,L,1\n",
    "        #下面计算的时候，mean会自动广播为N,L,D，self.a_2会自动广播为1,1,D\n",
    "        #是从右向左广播\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "#实现残差和层归一化标准组件\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    pre-layer_norm\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        #注意，此处的实现和论文内不一样，属于pre_LN，即在输入到注意力网络前，应用层归一化\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#实现前馈神经网络，FFN，即先升维再降维\n",
    "#d_ff一般设置为2048或者3072\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义输出头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成头，即将模型输出的形状N,L,D，映射为N,L,D,V,其中V是词典大小，便于后面计算损失\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.proj(x)\n",
    "        return F.log_softmax( out, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义编码层和编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义编码器层\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "#基于编码器层，定义编码器\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        #对encoder编码器最终的输出，再加一层层归一化，确保输出在特征维度分布稳定\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义解码层和解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义下三角掩码矩阵\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "\n",
    "        #和encoder类似，对dencoder解码器最终的输出，再加一层层归一化，确保输出在特征维度分布稳定\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义编码解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#组装成encoder-decoder\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义辅助工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型组装函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个函数，专门用来获取最终的Transformer模型\n",
    "\n",
    "def make_model(src_vocab, tgt_vocab, N=1, \n",
    "               d_model=128, d_ff=512, h=1, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    #对模型内，只要维度大于1的参数，均做xavier初始化\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL散度计算公式：\n",
    "* $Q为目标概率分布，P为模型输出， KL(Q,P)  = \\sum_{i} Q_{i} ( log(Q_{i}) - log(P_{i}) )  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个支持平滑的损失函数，基于KL散度\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        #下面使用的是kl散度损失，不是交叉熵损失，应该主要是考虑训练模型输出和目标的概率分布就行，但其实应该使用交叉熵\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')  \n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        \n",
    "        assert x.size(1) == self.size  #x的形状为N,L,C\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)  #沿着指定的dim轴，将self.confidence值，赋值给index指定的位置\n",
    "        # true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "            \n",
    "        self.true_dist = true_dist  #self.true_dist，最终的数据形状为  N,C ，其中C为分类数量，代表每个样本属于指定分类的概率值\n",
    "        \n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#很有参考价值\n",
    "class NoamOpt:\n",
    "    #自定义一个优化器，且支持自动调整学习率\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        #对优化器内的待优化参数进行遍历，每个待优化参数组，都有独立的学习率等参数，可以根据需要灵活调整\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        #作用类似于学习率调度器，专门用来计算学习率，供优化器使用\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失值计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "class SimpleLossCompute:\n",
    "    #用来计算\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self,generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(self.opt.optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # loss.backward()\n",
    "        \n",
    "        if self.opt is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                                            self.opt.optimizer.param_groups[0]['params'], \n",
    "                                            max_norm=1.0)  # 这里的 max_norm 是裁剪的阈值\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item() * norm\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "def print_cuda_mem(tag=\"\"):\n",
    "    print(f\"[{tag}] Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB, \"\n",
    "          f\"Reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "#统一训练工具\n",
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    max_token_len = 0\n",
    "    model = model.to(device)\n",
    "\n",
    "    #下面添加监控，包括对GPU使用的监控\n",
    "    with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=2),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./result', worker_name='worker0'),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,  # This will take 1 to 2 minutes. Setting it to False could greatly speedup.\n",
    "    with_stack=True\n",
    ") as p:\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            #收集训练数据内最大序列长度\n",
    "            batch_max_len =max(batch.src.shape[1],batch.trg.shape[1])\n",
    "            max_token_len = batch_max_len if batch_max_len > max_token_len else max_token_len\n",
    "            print(f'[step：{i}] 当前训练数据长度为{batch_max_len}')\n",
    "            #控制最大长度，避免显存爆炸\n",
    "            # maxlen = 150\n",
    "            # if batch_max_len > maxlen:\n",
    "            #     print(f'当前训练数据长度为{batch_max_len}大于{maxlen}，跳过该条数据')\n",
    "            #     continue\n",
    "            \n",
    "            batch.src = batch.src.to(device)\n",
    "            batch.trg = batch.trg.to(device)\n",
    "            batch.src_mask = batch.src_mask.to(device)\n",
    "            batch.trg_mask = batch.trg_mask.to(device)\n",
    "            batch.trg_y = batch.trg_y.to(device)\n",
    "            batch.ntokens = batch.ntokens.to(device)\n",
    "            # with torch.autocast(device_type=\"cuda\"):\n",
    "            \n",
    "            with autocast(device_type = device,dtype=torch.float16):\n",
    "                # out = checkpoint(model, batch.src, batch.trg, \n",
    "                #                     batch.src_mask, batch.trg_mask)\n",
    "                out = model.forward(batch.src, batch.trg, \n",
    "                                    batch.src_mask, batch.trg_mask)\n",
    "                loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "    \n",
    "            total_loss += loss\n",
    "            total_tokens += batch.ntokens\n",
    "            tokens += batch.ntokens\n",
    "\n",
    "            p.step()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(  \"[Step：{0}]  Loss: {1} Tokens per Sec: {2}\".format(i, loss.cpu() / batch.ntokens.cpu(), tokens / elapsed)  )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "            print(f'[Step：{i}]  当前记录序列最大长度{max_token_len}')\n",
    "            print_cuda_mem(f\"Step：{i}\")\n",
    "\n",
    "            \n",
    "    return total_loss.cpu() / total_tokens.cpu(),max_token_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义封装batch数据函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    #返回一个批次数据，数据形状还是N,L，待输入给模型\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)  #mask数据形状为N,1,L,之所以加1，是因为考虑到注意力加mask的时候，注意力矩阵是L，L的，所以搞成N，1，L，便于广播\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]  #模型的解码器输入，\n",
    "            self.trg_y = trg[:, 1:]  \n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        #返回一个下三角掩码矩阵，标准型的，主要给解码器使用\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用随机生成数据进行模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义随机数据生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch_size, 10)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.9025), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.7637), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.6535), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.6232), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.4635), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.2433), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.2499), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.1452), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(2.1164), 10)\n",
      "[step：0] 当前训练数据长度为10\n",
      "[step：0] 当前训练数据长度为10\n",
      "(tensor(1.9853), 10)\n"
     ]
    }
   ],
   "source": [
    "V = 11  #定义字典大小\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    run_epoch(data_gen(V, 30,  1), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    model.eval()\n",
    "    print(run_epoch(data_gen(V, 30, 1), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, model_opt)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用真实数据进行模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m LabelSmoothing(size\u001b[38;5;241m=\u001b[39mV_zh, padding_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m make_model(V_en, V_zh, N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m inputdata \u001b[38;5;241m=\u001b[39m [\u001b[43mbatch\u001b[49m\u001b[38;5;241m.\u001b[39msrc, batch\u001b[38;5;241m.\u001b[39mtrg, batch\u001b[38;5;241m.\u001b[39msrc_mask, batch\u001b[38;5;241m.\u001b[39mtrg_mask]\n\u001b[1;32m     11\u001b[0m summary(model,input_data \u001b[38;5;241m=\u001b[39minputdata  )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "V_zh = 12203 + 2\n",
    "V_en = 30684 + 2\n",
    "V = V_en\n",
    "\n",
    "criterion = LabelSmoothing(size=V_zh, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V_en, V_zh, N=1)\n",
    "\n",
    "inputdata = [batch.src, batch.trg, batch.src_mask, batch.trg_mask]\n",
    "summary(model,input_data =inputdata  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义字典和padding函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def get_dict(filename, pad=0, bos=1, eos=2, unk=3):\n",
    "    token_map = {\"<PAD>\": 0, \"<BOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "    with open(filename) as f:\n",
    "        for i, l in enumerate(f, start=4):\n",
    "            keys = l.strip().split()\n",
    "            token_map[keys[0]] = i\n",
    "    return token_map\n",
    "\n",
    "def batch_padding(batch, padding_idx=0):\n",
    "    max_len = len(max(batch, key=lambda x: len(x)))\n",
    "    for sent in batch:\n",
    "        padding_len = max_len - len(sent)\n",
    "        if padding_len:\n",
    "            sent.extend([padding_idx] * padding_len)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义真实训练数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def real_data_gen(V, batch_size):\n",
    "    \n",
    "    dict_zh = get_dict(\"dict.zh-cn\")\n",
    "    dict_en = get_dict(\"dict.en\")\n",
    "\n",
    "    train_en = open(\"./ted-data/train.en.bped\")\n",
    "    train_zh = open(\"./ted-data/train.zh-cn.bped\")\n",
    "\n",
    "    batch_en = []\n",
    "    batch_zh = []\n",
    "    \n",
    "    for sent_en, sent_zh in zip(train_en, train_zh):\n",
    "        sent_en = \"<BOS> {} <EOS>\".format(sent_en.strip())\n",
    "        sent_zh = \"<BOS> {} <EOS>\".format(sent_zh.strip())\n",
    "        batch_en.append([dict_en[token] for token in sent_en.split()])\n",
    "        batch_zh.append([dict_zh[token] for token in sent_zh.split()])\n",
    "        \n",
    "        if len(batch_en) % batch_size == 0:\n",
    "            src = torch.tensor(batch_padding(batch_en, 0), dtype=torch.int)\n",
    "            tgt = torch.tensor(batch_padding(batch_zh, 0), dtype=torch.int)\n",
    "            src = src.long()\n",
    "            tgt = tgt.long()\n",
    "            yield Batch(src, tgt, 0)\n",
    "    else:\n",
    "        src = src.long()\n",
    "        tgt = tgt.long()\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step：0] 当前训练数据长度为99\n",
      "[step：1] 当前训练数据长度为99\n",
      "[step：2] 当前训练数据长度为99\n",
      "[step：3] 当前训练数据长度为99\n",
      "[step：4] 当前训练数据长度为99\n",
      "[step：5] 当前训练数据长度为99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W530 14:59:46.052558139 CPUAllocator.cpp:245] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step：6] 当前训练数据长度为99\n",
      "[step：7] 当前训练数据长度为99\n",
      "[step：8] 当前训练数据长度为99\n",
      "[step：9] 当前训练数据长度为99\n",
      "[step：10] 当前训练数据长度为99\n",
      "[step：11] 当前训练数据长度为99\n",
      "[step：12] 当前训练数据长度为99\n",
      "[step：13] 当前训练数据长度为99\n",
      "[step：14] 当前训练数据长度为99\n",
      "[step：15] 当前训练数据长度为99\n",
      "[step：16] 当前训练数据长度为99\n",
      "[step：17] 当前训练数据长度为99\n",
      "[step：18] 当前训练数据长度为99\n",
      "[step：19] 当前训练数据长度为99\n",
      "[step：20] 当前训练数据长度为99\n",
      "[step：21] 当前训练数据长度为99\n",
      "[step：22] 当前训练数据长度为99\n",
      "[step：23] 当前训练数据长度为99\n",
      "[step：24] 当前训练数据长度为99\n",
      "[step：25] 当前训练数据长度为99\n",
      "[step：26] 当前训练数据长度为99\n",
      "[step：27] 当前训练数据长度为99\n",
      "[step：28] 当前训练数据长度为99\n",
      "[step：29] 当前训练数据长度为99\n",
      "[step：30] 当前训练数据长度为99\n",
      "[step：31] 当前训练数据长度为99\n",
      "[step：32] 当前训练数据长度为99\n",
      "[step：33] 当前训练数据长度为99\n",
      "[step：34] 当前训练数据长度为99\n",
      "[step：35] 当前训练数据长度为99\n",
      "[step：36] 当前训练数据长度为99\n",
      "[step：37] 当前训练数据长度为99\n",
      "[step：38] 当前训练数据长度为99\n",
      "[step：39] 当前训练数据长度为99\n",
      "[step：40] 当前训练数据长度为99\n",
      "[step：41] 当前训练数据长度为99\n",
      "[step：42] 当前训练数据长度为99\n",
      "[step：43] 当前训练数据长度为99\n",
      "[step：44] 当前训练数据长度为99\n",
      "[step：45] 当前训练数据长度为99\n",
      "[step：46] 当前训练数据长度为99\n",
      "[step：47] 当前训练数据长度为99\n",
      "[step：48] 当前训练数据长度为99\n",
      "[step：49] 当前训练数据长度为99\n",
      "[step：50] 当前训练数据长度为99\n",
      "[step：51] 当前训练数据长度为99\n",
      "[step：52] 当前训练数据长度为99\n",
      "[step：53] 当前训练数据长度为99\n",
      "[step：54] 当前训练数据长度为99\n",
      "[step：55] 当前训练数据长度为99\n",
      "[step：56] 当前训练数据长度为99\n",
      "[step：57] 当前训练数据长度为99\n",
      "[step：58] 当前训练数据长度为99\n",
      "[step：59] 当前训练数据长度为99\n",
      "[step：60] 当前训练数据长度为99\n",
      "[step：61] 当前训练数据长度为99\n",
      "[step：62] 当前训练数据长度为99\n",
      "[step：63] 当前训练数据长度为99\n",
      "[step：64] 当前训练数据长度为99\n",
      "[step：65] 当前训练数据长度为99\n",
      "[step：66] 当前训练数据长度为99\n",
      "[step：67] 当前训练数据长度为99\n",
      "[step：68] 当前训练数据长度为99\n",
      "[step：69] 当前训练数据长度为99\n",
      "[step：70] 当前训练数据长度为99\n",
      "[step：71] 当前训练数据长度为99\n",
      "[step：72] 当前训练数据长度为99\n",
      "[step：73] 当前训练数据长度为99\n",
      "[step：74] 当前训练数据长度为99\n",
      "[step：75] 当前训练数据长度为99\n",
      "[step：76] 当前训练数据长度为99\n",
      "[step：77] 当前训练数据长度为99\n",
      "[step：78] 当前训练数据长度为99\n",
      "[step：79] 当前训练数据长度为99\n",
      "[step：80] 当前训练数据长度为99\n",
      "[step：81] 当前训练数据长度为99\n",
      "[step：82] 当前训练数据长度为99\n",
      "[step：83] 当前训练数据长度为99\n",
      "[step：84] 当前训练数据长度为99\n",
      "[step：85] 当前训练数据长度为99\n",
      "[step：86] 当前训练数据长度为99\n",
      "[step：87] 当前训练数据长度为99\n",
      "[step：88] 当前训练数据长度为99\n",
      "[step：89] 当前训练数据长度为99\n",
      "[step：90] 当前训练数据长度为99\n",
      "[step：91] 当前训练数据长度为99\n",
      "[step：92] 当前训练数据长度为99\n",
      "[step：93] 当前训练数据长度为99\n",
      "[step：94] 当前训练数据长度为99\n",
      "[step：95] 当前训练数据长度为99\n",
      "[step：96] 当前训练数据长度为99\n",
      "[step：97] 当前训练数据长度为99\n",
      "[step：98] 当前训练数据长度为99\n",
      "[step：99] 当前训练数据长度为99\n",
      "[step：100] 当前训练数据长度为99\n",
      "[step：101] 当前训练数据长度为99\n",
      "[step：102] 当前训练数据长度为99\n",
      "[step：103] 当前训练数据长度为99\n",
      "[step：104] 当前训练数据长度为99\n",
      "[step：105] 当前训练数据长度为99\n",
      "[step：106] 当前训练数据长度为99\n",
      "[step：107] 当前训练数据长度为99\n",
      "[step：108] 当前训练数据长度为99\n",
      "[step：109] 当前训练数据长度为99\n",
      "[step：110] 当前训练数据长度为99\n",
      "[step：111] 当前训练数据长度为99\n",
      "[step：112] 当前训练数据长度为99\n",
      "[step：113] 当前训练数据长度为99\n",
      "[step：114] 当前训练数据长度为99\n",
      "[step：115] 当前训练数据长度为99\n",
      "[step：116] 当前训练数据长度为99\n",
      "[step：117] 当前训练数据长度为99\n",
      "[step：118] 当前训练数据长度为99\n",
      "[step：119] 当前训练数据长度为99\n",
      "[step：120] 当前训练数据长度为99\n",
      "[step：121] 当前训练数据长度为99\n",
      "[step：122] 当前训练数据长度为99\n",
      "[step：123] 当前训练数据长度为99\n",
      "[step：124] 当前训练数据长度为99\n",
      "[step：125] 当前训练数据长度为99\n",
      "[step：126] 当前训练数据长度为99\n",
      "[step：127] 当前训练数据长度为99\n",
      "[step：128] 当前训练数据长度为99\n",
      "[step：129] 当前训练数据长度为99\n",
      "[step：130] 当前训练数据长度为99\n",
      "[step：131] 当前训练数据长度为102\n",
      "[step：132] 当前训练数据长度为102\n",
      "[step：133] 当前训练数据长度为102\n",
      "[step：134] 当前训练数据长度为102\n",
      "[step：135] 当前训练数据长度为102\n",
      "[step：136] 当前训练数据长度为102\n",
      "[step：137] 当前训练数据长度为102\n",
      "[step：138] 当前训练数据长度为102\n",
      "[step：139] 当前训练数据长度为102\n",
      "[step：140] 当前训练数据长度为102\n",
      "[step：141] 当前训练数据长度为102\n",
      "[step：142] 当前训练数据长度为102\n",
      "[step：143] 当前训练数据长度为102\n",
      "[step：144] 当前训练数据长度为102\n",
      "[step：145] 当前训练数据长度为102\n",
      "[step：146] 当前训练数据长度为102\n",
      "[step：147] 当前训练数据长度为102\n",
      "[step：148] 当前训练数据长度为102\n",
      "[step：149] 当前训练数据长度为102\n",
      "[step：150] 当前训练数据长度为102\n",
      "[step：151] 当前训练数据长度为102\n",
      "[step：152] 当前训练数据长度为102\n",
      "[step：153] 当前训练数据长度为102\n",
      "[step：154] 当前训练数据长度为102\n",
      "[step：155] 当前训练数据长度为102\n",
      "[step：156] 当前训练数据长度为102\n",
      "[step：157] 当前训练数据长度为102\n",
      "[step：158] 当前训练数据长度为102\n",
      "[step：159] 当前训练数据长度为102\n",
      "[step：160] 当前训练数据长度为102\n",
      "[step：161] 当前训练数据长度为102\n",
      "[step：162] 当前训练数据长度为102\n",
      "[step：163] 当前训练数据长度为102\n",
      "[step：164] 当前训练数据长度为102\n",
      "[step：165] 当前训练数据长度为102\n",
      "[step：166] 当前训练数据长度为102\n",
      "[step：167] 当前训练数据长度为102\n",
      "[step：168] 当前训练数据长度为102\n",
      "[step：169] 当前训练数据长度为102\n",
      "[step：170] 当前训练数据长度为102\n",
      "[step：171] 当前训练数据长度为102\n",
      "[step：172] 当前训练数据长度为102\n",
      "[step：173] 当前训练数据长度为102\n",
      "[step：174] 当前训练数据长度为102\n",
      "[step：175] 当前训练数据长度为102\n",
      "[step：176] 当前训练数据长度为102\n",
      "[step：177] 当前训练数据长度为102\n",
      "[step：178] 当前训练数据长度为102\n",
      "[step：179] 当前训练数据长度为102\n",
      "[step：180] 当前训练数据长度为102\n",
      "[step：181] 当前训练数据长度为102\n",
      "[step：182] 当前训练数据长度为102\n",
      "[step：183] 当前训练数据长度为102\n",
      "[step：184] 当前训练数据长度为102\n",
      "[step：185] 当前训练数据长度为102\n",
      "[step：186] 当前训练数据长度为102\n",
      "[step：187] 当前训练数据长度为102\n",
      "[step：188] 当前训练数据长度为102\n",
      "[step：189] 当前训练数据长度为102\n",
      "[step：190] 当前训练数据长度为102\n",
      "[step：191] 当前训练数据长度为102\n",
      "[step：192] 当前训练数据长度为102\n",
      "[step：193] 当前训练数据长度为102\n",
      "[step：194] 当前训练数据长度为102\n",
      "[step：195] 当前训练数据长度为102\n",
      "[step：196] 当前训练数据长度为102\n",
      "[step：197] 当前训练数据长度为102\n",
      "[step：198] 当前训练数据长度为102\n",
      "[step：199] 当前训练数据长度为102\n",
      "[step：200] 当前训练数据长度为102\n",
      "[step：201] 当前训练数据长度为102\n",
      "[step：202] 当前训练数据长度为102\n",
      "[step：203] 当前训练数据长度为102\n",
      "[step：204] 当前训练数据长度为102\n",
      "[step：205] 当前训练数据长度为102\n",
      "[step：206] 当前训练数据长度为102\n",
      "[step：207] 当前训练数据长度为102\n",
      "[step：208] 当前训练数据长度为102\n",
      "[step：209] 当前训练数据长度为102\n",
      "[step：210] 当前训练数据长度为102\n",
      "[step：211] 当前训练数据长度为102\n",
      "[step：212] 当前训练数据长度为102\n",
      "[step：213] 当前训练数据长度为102\n",
      "[step：214] 当前训练数据长度为102\n",
      "[step：215] 当前训练数据长度为102\n",
      "[step：216] 当前训练数据长度为102\n",
      "[step：217] 当前训练数据长度为102\n",
      "[step：218] 当前训练数据长度为102\n",
      "[step：219] 当前训练数据长度为102\n",
      "[step：220] 当前训练数据长度为102\n",
      "[step：221] 当前训练数据长度为102\n",
      "[step：222] 当前训练数据长度为102\n",
      "[step：223] 当前训练数据长度为102\n",
      "[step：224] 当前训练数据长度为102\n",
      "[step：225] 当前训练数据长度为102\n",
      "[step：226] 当前训练数据长度为102\n",
      "[step：227] 当前训练数据长度为102\n",
      "[step：228] 当前训练数据长度为102\n",
      "[step：229] 当前训练数据长度为102\n",
      "[step：230] 当前训练数据长度为102\n",
      "[step：231] 当前训练数据长度为102\n",
      "[step：232] 当前训练数据长度为102\n",
      "[step：233] 当前训练数据长度为102\n",
      "[step：234] 当前训练数据长度为102\n",
      "[step：235] 当前训练数据长度为102\n",
      "[step：236] 当前训练数据长度为102\n",
      "[step：237] 当前训练数据长度为102\n",
      "[step：238] 当前训练数据长度为102\n",
      "[step：239] 当前训练数据长度为102\n",
      "[step：240] 当前训练数据长度为102\n",
      "[step：241] 当前训练数据长度为102\n",
      "[step：242] 当前训练数据长度为102\n",
      "[step：243] 当前训练数据长度为102\n",
      "[step：244] 当前训练数据长度为102\n",
      "[step：245] 当前训练数据长度为102\n",
      "[step：246] 当前训练数据长度为102\n",
      "[step：247] 当前训练数据长度为102\n",
      "[step：248] 当前训练数据长度为102\n",
      "[step：249] 当前训练数据长度为102\n",
      "[step：250] 当前训练数据长度为102\n",
      "[step：251] 当前训练数据长度为102\n",
      "[step：252] 当前训练数据长度为102\n",
      "[step：253] 当前训练数据长度为102\n",
      "[step：254] 当前训练数据长度为102\n",
      "[step：255] 当前训练数据长度为102\n",
      "[step：256] 当前训练数据长度为102\n",
      "[step：257] 当前训练数据长度为102\n",
      "[step：258] 当前训练数据长度为102\n",
      "[step：259] 当前训练数据长度为102\n",
      "[step：260] 当前训练数据长度为102\n",
      "[step：261] 当前训练数据长度为102\n",
      "[step：262] 当前训练数据长度为102\n",
      "[step：263] 当前训练数据长度为102\n",
      "[step：264] 当前训练数据长度为102\n",
      "[step：265] 当前训练数据长度为102\n",
      "[step：266] 当前训练数据长度为102\n",
      "[step：267] 当前训练数据长度为102\n",
      "[step：268] 当前训练数据长度为102\n",
      "[step：269] 当前训练数据长度为102\n",
      "[step：270] 当前训练数据长度为102\n",
      "[step：271] 当前训练数据长度为102\n",
      "[step：272] 当前训练数据长度为102\n",
      "[step：273] 当前训练数据长度为102\n",
      "[step：274] 当前训练数据长度为102\n",
      "[step：275] 当前训练数据长度为102\n",
      "[step：276] 当前训练数据长度为102\n",
      "[step：277] 当前训练数据长度为102\n",
      "[step：278] 当前训练数据长度为102\n",
      "[step：279] 当前训练数据长度为102\n",
      "[step：280] 当前训练数据长度为102\n",
      "[step：281] 当前训练数据长度为102\n",
      "[step：282] 当前训练数据长度为102\n",
      "[step：283] 当前训练数据长度为102\n",
      "[step：284] 当前训练数据长度为102\n",
      "[step：285] 当前训练数据长度为102\n",
      "[step：286] 当前训练数据长度为102\n",
      "[step：287] 当前训练数据长度为102\n",
      "[step：288] 当前训练数据长度为102\n",
      "[step：289] 当前训练数据长度为102\n",
      "[step：290] 当前训练数据长度为102\n",
      "[step：291] 当前训练数据长度为102\n",
      "[step：292] 当前训练数据长度为102\n",
      "[step：293] 当前训练数据长度为102\n",
      "[step：294] 当前训练数据长度为102\n",
      "[step：295] 当前训练数据长度为102\n",
      "[step：296] 当前训练数据长度为102\n",
      "[step：297] 当前训练数据长度为102\n",
      "[step：298] 当前训练数据长度为102\n",
      "[step：299] 当前训练数据长度为102\n",
      "[step：300] 当前训练数据长度为102\n",
      "[step：301] 当前训练数据长度为102\n",
      "[step：302] 当前训练数据长度为102\n",
      "[step：303] 当前训练数据长度为102\n",
      "[step：304] 当前训练数据长度为102\n",
      "[step：305] 当前训练数据长度为102\n",
      "[step：306] 当前训练数据长度为102\n",
      "[step：307] 当前训练数据长度为102\n",
      "[step：308] 当前训练数据长度为102\n",
      "[step：309] 当前训练数据长度为102\n",
      "[step：310] 当前训练数据长度为102\n",
      "[step：311] 当前训练数据长度为156\n",
      "[step：312] 当前训练数据长度为156\n",
      "[step：313] 当前训练数据长度为156\n",
      "[step：314] 当前训练数据长度为156\n",
      "[step：315] 当前训练数据长度为156\n",
      "[step：316] 当前训练数据长度为156\n",
      "[step：317] 当前训练数据长度为156\n",
      "[step：318] 当前训练数据长度为156\n",
      "[step：319] 当前训练数据长度为156\n",
      "[step：320] 当前训练数据长度为156\n",
      "[step：321] 当前训练数据长度为156\n",
      "[step：322] 当前训练数据长度为156\n",
      "[step：323] 当前训练数据长度为156\n",
      "[step：324] 当前训练数据长度为156\n",
      "[step：325] 当前训练数据长度为156\n",
      "[step：326] 当前训练数据长度为156\n",
      "[step：327] 当前训练数据长度为156\n",
      "[step：328] 当前训练数据长度为156\n",
      "[step：329] 当前训练数据长度为156\n",
      "[step：330] 当前训练数据长度为156\n",
      "[step：331] 当前训练数据长度为156\n",
      "[step：332] 当前训练数据长度为156\n",
      "[step：333] 当前训练数据长度为156\n",
      "[step：334] 当前训练数据长度为156\n",
      "[step：335] 当前训练数据长度为156\n",
      "[step：336] 当前训练数据长度为156\n",
      "[step：337] 当前训练数据长度为156\n",
      "[step：338] 当前训练数据长度为156\n",
      "[step：339] 当前训练数据长度为156\n",
      "[step：340] 当前训练数据长度为156\n",
      "[step：341] 当前训练数据长度为156\n",
      "[step：342] 当前训练数据长度为156\n",
      "[step：343] 当前训练数据长度为156\n",
      "[step：344] 当前训练数据长度为156\n",
      "[step：345] 当前训练数据长度为156\n",
      "[step：346] 当前训练数据长度为156\n",
      "[step：347] 当前训练数据长度为156\n",
      "[step：348] 当前训练数据长度为156\n",
      "[step：349] 当前训练数据长度为156\n",
      "[step：350] 当前训练数据长度为156\n",
      "[step：351] 当前训练数据长度为156\n",
      "[step：352] 当前训练数据长度为156\n",
      "[step：353] 当前训练数据长度为156\n",
      "[step：354] 当前训练数据长度为156\n",
      "[step：355] 当前训练数据长度为156\n",
      "[step：356] 当前训练数据长度为156\n",
      "[step：357] 当前训练数据长度为156\n",
      "[step：358] 当前训练数据长度为156\n",
      "[step：359] 当前训练数据长度为156\n",
      "[step：360] 当前训练数据长度为156\n",
      "[step：361] 当前训练数据长度为156\n",
      "[step：362] 当前训练数据长度为156\n",
      "[step：363] 当前训练数据长度为156\n",
      "[step：364] 当前训练数据长度为156\n",
      "[step：365] 当前训练数据长度为156\n",
      "[step：366] 当前训练数据长度为156\n",
      "[step：367] 当前训练数据长度为156\n",
      "[step：368] 当前训练数据长度为156\n",
      "[step：369] 当前训练数据长度为156\n",
      "[step：370] 当前训练数据长度为156\n",
      "[step：371] 当前训练数据长度为156\n",
      "[step：372] 当前训练数据长度为156\n",
      "[step：373] 当前训练数据长度为156\n",
      "[step：374] 当前训练数据长度为156\n",
      "[step：375] 当前训练数据长度为156\n",
      "[step：376] 当前训练数据长度为156\n",
      "[step：377] 当前训练数据长度为156\n",
      "[step：378] 当前训练数据长度为156\n",
      "[step：379] 当前训练数据长度为156\n",
      "[step：380] 当前训练数据长度为156\n",
      "[step：381] 当前训练数据长度为156\n",
      "[step：382] 当前训练数据长度为156\n",
      "[step：383] 当前训练数据长度为156\n",
      "[step：384] 当前训练数据长度为156\n",
      "[step：385] 当前训练数据长度为156\n",
      "[step：386] 当前训练数据长度为156\n",
      "[step：387] 当前训练数据长度为156\n",
      "[step：388] 当前训练数据长度为156\n",
      "[step：389] 当前训练数据长度为156\n",
      "[step：390] 当前训练数据长度为156\n",
      "[step：391] 当前训练数据长度为156\n",
      "[step：392] 当前训练数据长度为156\n",
      "[step：393] 当前训练数据长度为156\n",
      "[step：394] 当前训练数据长度为156\n",
      "[step：395] 当前训练数据长度为156\n",
      "[step：396] 当前训练数据长度为156\n",
      "[step：397] 当前训练数据长度为156\n",
      "[step：398] 当前训练数据长度为156\n",
      "[step：399] 当前训练数据长度为156\n",
      "[step：400] 当前训练数据长度为156\n",
      "[step：401] 当前训练数据长度为156\n",
      "[step：402] 当前训练数据长度为156\n",
      "[step：403] 当前训练数据长度为156\n",
      "[step：404] 当前训练数据长度为156\n",
      "[step：405] 当前训练数据长度为156\n",
      "[step：406] 当前训练数据长度为156\n",
      "[step：407] 当前训练数据长度为156\n",
      "[step：408] 当前训练数据长度为156\n",
      "[step：409] 当前训练数据长度为156\n",
      "[step：410] 当前训练数据长度为156\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.92 GiB. GPU 0 has a total capacity of 23.63 GiB of which 2.88 GiB is free. Process 4073 has 536.00 MiB memory in use. Process 4074 has 1.36 GiB memory in use. Process 4067 has 346.00 MiB memory in use. Process 659678 has 462.00 MiB memory in use. Process 2272425 has 3.78 GiB memory in use. Including non-PyTorch memory, this process has 14.28 GiB memory in use. Of the allocated memory 13.27 GiB is allocated by PyTorch, and 593.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m              \u001b[49m\u001b[43mSimpleLossCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_opt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# model.eval()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# print(run_epoch(real_data_gen(V, 1), model, \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#                 SimpleLossCompute(model.generator, criterion, None)))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 56\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, loss_compute)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type \u001b[38;5;241m=\u001b[39m device,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# out = checkpoint(model, batch.src, batch.trg, \u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#                     batch.src_mask, batch.trg_mask)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(batch\u001b[38;5;241m.\u001b[39msrc, batch\u001b[38;5;241m.\u001b[39mtrg, \n\u001b[1;32m     55\u001b[0m                         batch\u001b[38;5;241m.\u001b[39msrc_mask, batch\u001b[38;5;241m.\u001b[39mtrg_mask)\n\u001b[0;32m---> 56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrg_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mntokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     59\u001b[0m total_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mntokens\n",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m, in \u001b[0;36mSimpleLossCompute.__call__\u001b[0;34m(self, x, y, norm)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, norm):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(x)\n\u001b[0;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m norm\n\u001b[1;32m     16\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39moptimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m, in \u001b[0;36mLabelSmoothing.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     23\u001b[0m     true_dist\u001b[38;5;241m.\u001b[39mindex_fill_(\u001b[38;5;241m0\u001b[39m, mask\u001b[38;5;241m.\u001b[39msqueeze(), \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_dist \u001b[38;5;241m=\u001b[39m true_dist  \u001b[38;5;66;03m#self.true_dist，最终的数据形状为  N,C ，其中C为分类数量，代表每个样本属于指定分类的概率值\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/modules/loss.py:543\u001b[0m, in \u001b[0;36mKLDivLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_target\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/books/lib/python3.10/site-packages/torch/nn/functional.py:3396\u001b[0m, in \u001b[0;36mkl_div\u001b[0;34m(input, target, size_average, reduce, reduction, log_target)\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3394\u001b[0m         reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m-> 3396\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3399\u001b[0m     reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.92 GiB. GPU 0 has a total capacity of 23.63 GiB of which 2.88 GiB is free. Process 4073 has 536.00 MiB memory in use. Process 4074 has 1.36 GiB memory in use. Process 4067 has 346.00 MiB memory in use. Process 659678 has 462.00 MiB memory in use. Process 2272425 has 3.78 GiB memory in use. Including non-PyTorch memory, this process has 14.28 GiB memory in use. Of the allocated memory 13.27 GiB is allocated by PyTorch, and 593.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "# wc -l dict.en dict.zh-cn\n",
    "V_zh = 12203 + 2\n",
    "V_en = 30684 + 2\n",
    "V = V_en\n",
    "\n",
    "criterion = LabelSmoothing(size=V_zh, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V_en, V_zh, N=1)\n",
    "# model = model.to(torch.float16)\n",
    "\n",
    "# model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "#         torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.SGD(model.parameters(), lr=0))\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    run_epoch(real_data_gen(V,  1 ), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    # model.eval()\n",
    "    # print(run_epoch(real_data_gen(V, 1), model, \n",
    "    #                 SimpleLossCompute(model.generator, criterion, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = real_data_gen(V, 1 )\n",
    "batch = next(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m max_l_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m      3\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(batch\u001b[38;5;241m.\u001b[39msrc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],batch\u001b[38;5;241m.\u001b[39mtrg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m     max_l_len \u001b[38;5;241m=\u001b[39m temp \u001b[38;5;28;01mif\u001b[39;00m temp \u001b[38;5;241m>\u001b[39m max_l_len \u001b[38;5;28;01melse\u001b[39;00m max_l_len\n",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m, in \u001b[0;36mreal_data_gen\u001b[0;34m(V, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch_en) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_padding(batch_en, \u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m---> 20\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_padding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_zh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     22\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m tgt\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_l_len = 0\n",
    "for batch in datasets:\n",
    "    temp = max(batch.src.shape[1],batch.trg.shape[1])\n",
    "    max_l_len = temp if temp > max_l_len else max_l_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_l_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "books",
   "language": "python",
   "name": "books"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
